# MedDQA benchmark
Official repository of [[RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning](https://arxiv.org/abs/2402.14840)] 
<p align="center">
    <img src="pics/1.png" width="50%"> <br>
  * Complex Page Layouts in Various Medical Report Categories: Four Illustrative Examples *
</p>

# About MedDQA
The RJUA-MedDQA dataset contains a total of 2000 images, of which 402 are screenshot, 619 are scanned-PDF, and the remaining 979 are photos taken by patients. Reports in screenshot and scanned-PDF format ensure the integrity and clarity of information; on the other hand, reports captured in photographs may exhibit some degree of quality degradation caused by issues such as rotated or skewed angles, blurred text, or incomplete information, which reveals real-world problems. Medical reports can be grouped into two main categories, namely
Laboratory Report and Diagnostic(Clinical) Report. 

<p align="center">
    <img src="pics/2.png" width="50%"> <br>
  * Statistics by report types *
</p>


## Acknowledgement

If you find LLaVA-Med useful for your your research and applications, please cite using this BibTeX:
```bibtex
@misc{jin2024rjuameddqa,
      title={RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning}, 
      author={Congyun Jin and Ming Zhang and Xiaowei Ma and Li Yujiao and Yingbo Wang and Yabo Jia and Yuliang Du and Tao Sun and Haowen Wang and Cong Fan and Jinjie Gu and Chenfei Chi and Xiangguo Lv and Fangzhou Li and Wei Xue and Yiran Huang},
      year={2024},
      eprint={2402.14840},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
